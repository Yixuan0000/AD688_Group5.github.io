---
title: "Multiple Linear Regression - Salary Predition"
subtitle: ""

bibliography: references.bib
csl: csl/econometrica.csl
format: 
  html:
    toc: true
    number-sections: true
    df-print: paged
    code: false
    code-tools: true
    section-divs: true
---

# Mutiple Linear Regression
```{python}
#| echo: false
import os, json
import pandas as pd
import numpy as np
import plotly.express as px
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import plotly.graph_objects as go
```

```{python}
#| echo: false
df = pd.read_csv('files/cleaned_job_postings.csv')
```

```{python}
#| echo: false
df.head()
```

```{python}
#| echo: false
#df.columns
```
```{python}
df["exp_mid"] = df[["MIN_YEARS_EXPERIENCE", "MAX_YEARS_EXPERIENCE"]].mean(axis=1)

df["skill_count"] = df["SPECIALIZED_SKILLS_NAME"].fillna("").str.count(",") + 1

df["has_python"] = df["SPECIALIZED_SKILLS_NAME"].str.contains("Python", case=False, na=False).astype(int)

df["edu_ge_bachelors"] = df["MIN_EDULEVELS_NAME"].isin(
    ["Bachelor's Degree", "Master's Degree", "Doctoral Degree"]
).astype(int)

keep_num  = ["exp_mid", "MODELED_DURATION", "skill_count",
             "has_python", "edu_ge_bachelors"]

keep_cat  = ["EMPLOYMENT_TYPE_NAME", "REMOTE_TYPE_NAME",
             "STATE_NAME", 
             "SOC_2021_4_NAME"]

df_model = (
    df.dropna(subset=["SALARY"])      
      .loc[:, keep_num + keep_cat + ["SALARY"]]  
)
```

```{python}
df_dummies = pd.get_dummies(
    df_model,
    columns = keep_cat,   
    drop_first = True,   
    dtype = float        
)
```


```{python}
#| echo: false
print(df_dummies.shape)
print(df_dummies.dtypes.head(10))
```

```{python}
# Drop salary to form features
X = df_dummies.drop('SALARY', axis = 1)
y = df_dummies['SALARY']

X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size = 0.3, random_state = 688)
```

```{python}
model = LinearRegression()
model.fit(X_train, y_train)
```

```{python}
y_pred = model.predict(X_test)
pd.Series(y_pred).describe()
```

```{python}
rmse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:.2f}")
print(f"R-squared: {r2:.4f}")
```

```{python}
coef_df = pd.DataFrame({
    "Feature": X.columns,
    "Coefficient": model.coef_
}).sort_values(by="Coefficient", ascending=False)

coef_df.head(10)
```

```{python}
coef_cleaned = coef_df[~coef_df['Feature'].str.contains("Unknown|\[None\]", regex=True)]

coef_cleaned.head(10)
```

# Visualization 

```{python}
#| echo: false
figures_folder = "figures"
if not os.path.exists(figures_folder):
    os.makedirs(figures_folder)
```
## Coefficient bar chart
```{python}
#| echo: false
# 1. Coefficient bar chart
fig = px.bar(coef_df, x="Coefficient", y="Feature", orientation="h",
             title="Top 15 Positive/Negative MLR Coefficients",
             template="plotly_white", width=800, height=550)
fig.update_yaxes(autorange="reversed")
fig.write_html(os.path.join(figures_folder, "MLR_Coefficients.html"))
```
<iframe src="figures/MLR_Coefficients.html" width="100%" height="550"></iframe>

## Actual vs. Predicted

```{python}
#| echo: false
# 2. Actual vs. Predicted
fig = go.Figure()
fig.add_trace(go.Scatter(
    x=y_test, y=y_pred, mode="markers", name="Observations",
    marker=dict(size=6, opacity=0.6)
))
lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]
fig.add_shape(type="line", x0=lims[0], y0=lims[0],
              x1=lims[1], y1=lims[1],
              line=dict(dash="dash", width=2, color="red"))
fig.update_layout(
    title="MLR – Actual vs. Predicted",
    xaxis_title="Actual Salary",
    yaxis_title="Predicted Salary",
    template="plotly_white", width=800, height=550
)
fig.write_html(os.path.join(figures_folder, "MLR_AVP.html"))
```
<iframe src="figures/MLR_AVP.html" width="100%" height="550"></iframe>

## Residual histogram
```{python}
#| echo: false
# 3. Residual histogram
resid = y_test - y_pred
fig = px.histogram(resid, nbins=40,
                   title="MLR Residual Distribution",
                   labels={"value":"Error (Actual – Predicted)"},
                   template="plotly_white", width=800, height=500)
fig.write_html(os.path.join(figures_folder, "MLR_Residuals.html"))
fig
```
<iframe src="figures/MLR_Residuals.html" width="100%" height="550"></iframe>

# Random Forest
```{python}
rf_model = RandomForestRegressor(
    n_estimators     = 300,
    min_samples_leaf = 2,
    random_state     = 688,
    n_jobs           = -1
)
rf_model.fit(X_train, y_train)
```

```{python}
rf_pred = rf_model.predict(X_test)
rf_rmse = mean_squared_error(y_test, rf_pred)
rf_r2   = r2_score(y_test, rf_pred)
print(f"Random Forest  •  RMSE = {rf_rmse:.2f}  |  R² = {rf_r2:.3f}")
```

## Rank Importance
```{python}
imp_df = (pd.Series(rf_model.feature_importances_, index=X_train.columns)
            .sort_values(ascending=False)
            .head(15)
            .reset_index()
            .rename(columns={"index": "Feature", 0: "Importance"}))

fig = px.bar(imp_df, x="Importance", y="Feature", orientation="h",
             title="Top 15 Random Forest Importances",
             template="plotly_white", width=800, height=550)
fig.update_yaxes(autorange="reversed")
fig.write_html(os.path.join(figures_folder, "RF_Importance.html"))
```
<iframe src="figures/RF_Importance.html" width="100%" height="550"></iframe>


# Unsupervised Learning - Kmeans 

```{python}
#| echo: false
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_dummies)
```

```{python}
#| echo: false
wcss = []
K_range = range(2, 11)

for k in K_range:
    km = KMeans(n_clusters=k, n_init=10, random_state=688)
    km.fit(X_scaled)
    wcss.append(km.inertia_)
```

## Elbow Plot

```{python}
#| echo: false
# Elbow Plot
fig = go.Figure()

fig.add_trace(go.Scatter(
    x=list(K_range),
    y=wcss,
    mode='lines+markers',
    marker=dict(size=8),
    line=dict(width=2),
    name='WCSS'
))

fig.update_layout(
    title='Elbow Method - Within-Cluster Sum of Squares',
    xaxis_title='Number of Clusters (k)',
    yaxis_title='WCSS',
    template='plotly_white',
    width=800,
    height=500
)

fig.write_html(os.path.join(figures_folder, "Elbow_Chart.html"))
```
<iframe src="figures/Elbow_Chart.html" width="100%" height="500"></iframe>
```{python}
# From the elbow Plot, we take k = 4
kmeans = KMeans(n_clusters=4, n_init=10, random_state=688)

cluster_labels = kmeans.fit_predict(X_scaled)

df['cluster'] = cluster_labels
```

```{python}
print(df['cluster'].value_counts().sort_index())
```